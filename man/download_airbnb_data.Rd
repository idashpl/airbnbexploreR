% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download_airbnb_data.R
\name{download_airbnb_data}
\alias{download_airbnb_data}
\title{Download airbnb many datasets at once}
\usage{
download_airbnb_data(dir = NULL, data_to_load = NULL, archived = FALSE,
  city = NULL, format = NULL, confirm_threshold = 20, unzip = FALSE)
}
\arguments{
\item{dir}{Directory to store downloaded data. If not specified, it will build
\code{airbnb_data/} directory.}

\item{data_to_load}{Names of datasets to download. Possible options:
`listings`, `calendar`, `reviews`. By default, it takes all of them into account.
A character scalar will save one dataset type, but by using vector it's possible
to define more dataset types.}

\item{archived}{Boolean option. Whether to download archived files as well.
By defualt,  \code{archived = FALSE} which means, it saves only the latest datasets.}

\item{city}{City name. The function will download only datasets related to the  \code{city}.
It could be character scalar or a vector with more cities. To see all available cities,
check \code{\link{extract_metadata}} function.}

\item{format}{Defined dataset format. Two options available:  \code{raw} which stores
raw data and  \code{summary} which have only the most important columns from raw data.
By default the function will download both formats.}

\item{confirm_threshold}{The user will be asked for confirmation when the number of datasets
to download exceeds the  \code{confirm_threshold}.}

\item{unzip}{Boolean option. Whether to uzip saved datasets.
This opiton is only useful in case of raw data..}
}
\description{
Scrape the \url{http://insideairbnb.com} webpage to download selected datasets.
}
\examples{
\dontrun{
download_airbnb_data(format = 'raw',
                     archived = TRUE,
                     data_to_load = c("listings", "calendar"),
                     unzip = TRUE,
                     city = c("Berlin", "Vienna"))
}
}
\seealso{
\code{\link{aux_download}}
}
